[Skip to content](https://github.com/daily-co/pipecat-cloud-images/tree/main/pipecat-starters/vision#start-of-content)

You signed in with another tab or window. [Reload](https://github.com/daily-co/pipecat-cloud-images/tree/main/pipecat-starters/vision) to refresh your session.You signed out in another tab or window. [Reload](https://github.com/daily-co/pipecat-cloud-images/tree/main/pipecat-starters/vision) to refresh your session.You switched accounts on another tab or window. [Reload](https://github.com/daily-co/pipecat-cloud-images/tree/main/pipecat-starters/vision) to refresh your session.Dismiss alert

[daily-co](https://github.com/daily-co)/ **[pipecat-cloud-images](https://github.com/daily-co/pipecat-cloud-images)** Public

- [Notifications](https://github.com/login?return_to=%2Fdaily-co%2Fpipecat-cloud-images) You must be signed in to change notification settings
- [Fork\\
1](https://github.com/login?return_to=%2Fdaily-co%2Fpipecat-cloud-images)
- [Star\\
5](https://github.com/login?return_to=%2Fdaily-co%2Fpipecat-cloud-images)


## Files

main

/

# vision

/

Copy path

## Directory actions

## More options

## Directory actions

## More options

## Latest commit

[![markbackman](https://avatars.githubusercontent.com/u/1924426?v=4&size=40)](https://github.com/markbackman)[markbackman](https://github.com/daily-co/pipecat-cloud-images/commits?author=markbackman)

[Update bot() docstrings to reflect correct args](https://github.com/daily-co/pipecat-cloud-images/commit/aea0e5436d9046153f18c64ffbe566765755a409)

Mar 13, 2025

[aea0e54](https://github.com/daily-co/pipecat-cloud-images/commit/aea0e5436d9046153f18c64ffbe566765755a409) · Mar 13, 2025

## History

[History](https://github.com/daily-co/pipecat-cloud-images/commits/main/pipecat-starters/vision)

/

# vision

/

Top

## Folders and files

| Name | Name | Last commit message | Last commit date |
| --- | --- | --- | --- |
| ### parent directory<br> [..](https://github.com/daily-co/pipecat-cloud-images/tree/main/pipecat-starters) |
| [Dockerfile](https://github.com/daily-co/pipecat-cloud-images/blob/main/pipecat-starters/vision/Dockerfile "Dockerfile") | [Dockerfile](https://github.com/daily-co/pipecat-cloud-images/blob/main/pipecat-starters/vision/Dockerfile "Dockerfile") | [Update base image in starters](https://github.com/daily-co/pipecat-cloud-images/commit/44d0e328ff42428f6b0260f4393aada51ff6febe "Update base image in starters") | Mar 5, 2025 |
| [README.md](https://github.com/daily-co/pipecat-cloud-images/blob/main/pipecat-starters/vision/README.md "README.md") | [README.md](https://github.com/daily-co/pipecat-cloud-images/blob/main/pipecat-starters/vision/README.md "README.md") | [Merged in main, moved starter images to correct folder](https://github.com/daily-co/pipecat-cloud-images/commit/2fe43a1f365f32876237412b4227835c37e5595b "Merged in main, moved starter images to correct folder") | Mar 5, 2025 |
| [bot.py](https://github.com/daily-co/pipecat-cloud-images/blob/main/pipecat-starters/vision/bot.py "bot.py") | [bot.py](https://github.com/daily-co/pipecat-cloud-images/blob/main/pipecat-starters/vision/bot.py "bot.py") | [Update bot() docstrings to reflect correct args](https://github.com/daily-co/pipecat-cloud-images/commit/aea0e5436d9046153f18c64ffbe566765755a409 "Update bot() docstrings to reflect correct args") | Mar 13, 2025 |
| [requirements.txt](https://github.com/daily-co/pipecat-cloud-images/blob/main/pipecat-starters/vision/requirements.txt "requirements.txt") | [requirements.txt](https://github.com/daily-co/pipecat-cloud-images/blob/main/pipecat-starters/vision/requirements.txt "requirements.txt") | [include pipecatcloud and make use of the new agent session arguments](https://github.com/daily-co/pipecat-cloud-images/commit/10f7608502a0d3667976c6b46d1817acf81ccfe1 "include pipecatcloud and make use of the new agent session arguments") | Mar 12, 2025 |
| View all files |

## [README.md](https://github.com/daily-co/pipecat-cloud-images/tree/main/pipecat-starters/vision\#readme)

# Vision Bot Starter

[Permalink: Vision Bot Starter](https://github.com/daily-co/pipecat-cloud-images/tree/main/pipecat-starters/vision#vision-bot-starter)

This repository contains a starter template for building a voice-based AI agent with vision capabilities using Pipecat and deploying it to Pipecat Cloud.

## Features

[Permalink: Features](https://github.com/daily-co/pipecat-cloud-images/tree/main/pipecat-starters/vision#features)

- A ready-to-run voice and vision bot powered by:
  - Anthropic Claude for language understanding and vision analysis (LLM)
  - Deepgram for speech-to-text (STT)
  - Cartesia for text-to-speech (TTS)
  - Daily for WebRTC audio/video transport
- Custom "get\_image" tool to request and analyze video frames
- Real-time voice activity detection (VAD) using Silero
- Complete Dockerfile for containerization

## Required API Keys

[Permalink: Required API Keys](https://github.com/daily-co/pipecat-cloud-images/tree/main/pipecat-starters/vision#required-api-keys)

- `ANTHROPIC_API_KEY`
- `DEEPGRAM_API_KEY`
- `CARTESIA_API_KEY`

## Customizing Your Bot

[Permalink: Customizing Your Bot](https://github.com/daily-co/pipecat-cloud-images/tree/main/pipecat-starters/vision#customizing-your-bot)

### Modifying Bot Behavior

[Permalink: Modifying Bot Behavior](https://github.com/daily-co/pipecat-cloud-images/tree/main/pipecat-starters/vision#modifying-bot-behavior)

The main logic for the bot is in `bot.py`. Here are key areas you might want to customize:

1. **Change the System Prompt**: Find the `system_prompt` variable and modify it to change your bot's personality and behavior.

```
system_prompt = """You are a helpful assistant who converses with a user and answers questions. Respond concisely to general questions.

Your response will be turned into speech so use only simple words and punctuation.

You have access to one tools: get_image.

You can answer questions about the user's video stream using the get_image tool. Some examples of phrases that indicate you should use the get_image tool are:
- What do you see?
- What's in the video?
- Can you describe the video?
- Tell me about what you see.
- Tell me something interesting about what you see.
- What's happening in the video?

If you need to use a tool, simply use the tool. Do not tell the user the tool you are using. Be brief and concise."""
```

2. **Change the Services and Options**: You can modify the STT, LLM, and TTS services and options.

```
stt = DeepgramSTTService(api_key=os.getenv("DEEPGRAM_API_KEY"))
llm = AnthropicLLMService(
    api_key=os.getenv("ANTHROPIC_API_KEY"),
    model="claude-3-5-sonnet-latest",
    enable_prompt_caching_beta=True,
)
tts = CartesiaTTSService(
    api_key=os.getenv("CARTESIA_API_KEY"),
    voice_id="79a125e8-cd45-4c13-8a67-188112f4dd22",
)
```

3. **Change Video Frame Rate**: Adjust the frame rate of the video capture to balance performance and quality.

```
# Adjust framerate (0 for on-demand frames, higher values for continuous capture)
await transport.capture_participant_video(video_participant_id, framerate=0)
```

### Understanding Vision Capabilities

[Permalink: Understanding Vision Capabilities](https://github.com/daily-co/pipecat-cloud-images/tree/main/pipecat-starters/vision#understanding-vision-capabilities)

This starter includes a custom implementation of the `AnthropicContextWithVisionTool` class that provides:

1. A "get\_image" tool for requesting current video frames
2. Integration between the Daily transport and Claude's vision capabilities
3. Dynamic frame capture based on conversation context

The bot can see what's on the user's camera and analyze visual content on-demand, allowing it to:

- Describe what it sees in the video
- Answer questions about visual content
- Provide insights based on the visual stream

### Adding New Capabilities

[Permalink: Adding New Capabilities](https://github.com/daily-co/pipecat-cloud-images/tree/main/pipecat-starters/vision#adding-new-capabilities)

To extend your bot's functionality:

1. **Add Tools/Function Calling**: Add additional tools by extending the existing tool implementation:

```
def _add_additional_tools(self):
    # Add your custom tools here
    self._tools.append(
        {
            "name": "your_tool_name",
            "description": "Description of your tool",
            "input_schema": {
                "type": "object",
                "properties": {
                    # Your tool properties
                },
                "required": ["required_properties"],
            },
        }
    )
```

2. **Add New Processors**: Modify the pipeline by adding new processors:

```
pipeline = Pipeline([\
    transport.input(),\
    rtvi,\
    stt,\
    # Add your custom processors here\
    context_aggregator.user(),\
    llm,\
    tts,\
    transport.output(),\
    context_aggregator.assistant(),\
])
```

Popular options include:

- [RTVIProcessor](https://docs.pipecat.ai/server/frameworks/rtvi/rtvi-processor): For client/server messaging and events
- [AudioBufferProcessor](https://docs.pipecat.ai/server/utilities/audio/audio-recording): Record audio in a call
- [TranscriptProcessor](https://docs.pipecat.ai/server/utilities/transcript-processor): Collect user and assistant transcripts
- [STTMuteFilter](https://docs.pipecat.ai/server/utilities/filters/stt-mute): Prevent the bot from being interrupted in specific scenarios
- [UserIdleProcessor](https://docs.pipecat.ai/server/utilities/user-idle-processor): Trigger a response when a user hasn't responded in a set period of time
- [Observers](https://docs.pipecat.ai/server/utilities/observers/observer-pattern): Debug issues by inspecting frames in the pipeline

## Deployment

[Permalink: Deployment](https://github.com/daily-co/pipecat-cloud-images/tree/main/pipecat-starters/vision#deployment)

See the [top-level README](https://github.com/daily-co/pipecat-cloud-images/blob/main/pipecat-starters/README.md) for deployment instructions.

You can’t perform that action at this time.